[config]
save_dir = "OneDTMaze_RR_ER"
exp_file = "experiments/1d-tmaze-er.jl"
exp_module_name = "OneDTmazeERExperiment"
exp_func_name = "main_experiment"
arg_iter_type = "iter"

[static_args]

steps = 30000

logger_keys = ["ONEDTMAZEERROR","ONEDTMAZEERROR_UNIFORM","ONEDTMAZEERROR_DPI", "ONED_GOAL_VISITATION", "EPISODE_LENGTH", "INTRINSIC_REWARD"]
logger_interval = 100
# Behaviour Items
behaviour_alpha_init = 0.1 # Will be 1/tilings from sweep
behaviour_gamma = 0.90
behaviour_reward_projector = "maze"
exploration_strategy = "epsilon_greedy"
# behaviour_trace = "AccumulatingTraces"
behaviour_lambda = 0.95
behaviour_w_init = 4.0

# Demon Attributes

demon_alpha_init = 0.1 # Will be 1/tilings from sweep
demon_discounts = 0.9
demon_lambda = 0.9
demon_policy_type = "greedy_to_cumulant"
demon_trace = "AccumulatingTraces"

demon_learner = "SR"
demon_rep = "ideal"

demon_opt = "Auto+ADAM"
demon_beta_m = 0.99
demon_beta_v = 0.999
# demon_update = "TB"
# demon_eta = 0.15
# demon_opt = "Auto"

# Environment Config
constant_target= [-10.0,10.0]
distractor = [1.0, 5.0]
drifter = [1.0, 0.1] # drifter is the sqrt(0.01)
# env_step_penalty = -0.01


# exploring_starts="beg"

# Agent and Logger
horde_type = "regular"
intrinsic_reward = "weight_change"

use_external_reward = true
random_first_action = true

# num_tilings = 8
behaviour_learner = "RoundRobin"
behaviour_opt = "Auto"
behaviour_update = "Q"
exploration_param = 0.1

replay_size = 10000


[sweep_args]
seed = "1:30"
cumulant_schedule = ["DrifterDistractor"]
eta = "2.0.^(-10:2:0)"
batch_size = [1, 4, 8]

demon_update = ["TB"]
tiling_structure = [[2,8]]
exploring_starts= ["whole"]
behaviour_trace = ["ReplacingTraces"]
env_step_penalty = [-0.01]
alpha_init = [0.01, 0.1, 0.2]