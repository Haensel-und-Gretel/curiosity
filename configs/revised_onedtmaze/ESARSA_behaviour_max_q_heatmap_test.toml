[config]
save_dir = "OneDTMaze_NEW_DYNAMICS_NEW_EVAL"
exp_file = "experiments/1d-tmaze.jl"
exp_module_name = "OneDTmazeExperiment"
exp_func_name = "main_experiment"
arg_iter_type = "iter"

[static_args]

steps = 40000

logger_keys = ["ONEDTMAZEERROR", "ONED_GOAL_VISITATION", "EPISODE_LENGTH", "ONED_STATE_VISITATION"]
logger_interval = 100
# Behaviour Items
behaviour_alpha_init = 0.1 # Will be 1/tilings from sweep
behaviour_gamma = 0.95
behaviour_reward_projector = "ideal_martha"
exploration_strategy = "epsilon_greedy"
behaviour_trace = "AccumulatingTraces"
behaviour_lambda = 0.90
behaviour_w_init = 1.0

# Demon Attributes

demon_alpha_init = 0.1 # Will be 1/tilings from sweep
demon_discounts = 0.9
demon_lambda = 0.9
demon_policy_type = "greedy_to_cumulant"
demon_trace = "AccumulatingTraces"

# demon_learner = "SR"
demon_rep = "ideal_martha"
# demon_update = "TB"
# demon_eta = 0.15
demon_opt = "Auto"

# Environment Config
constant_target= [-10.0,10.0]
distractor = [1.0, 5.0]
drifter = [1.0, 0.1] # drifter is the sqrt(0.01)
env_step_penalty = 0.000


# exploring_starts="beg"

# Agent and Logger
horde_type = "regular"
intrinsic_reward = "weight_change"

use_external_reward = true

# num_tilings = 8
# num_tiles = 2


[sweep_args]
seed = "1:20"
cumulant_schedule = ["DrifterDistractor"]
eta = "5.0.^(-2:-2)"
behaviour_opt = ["Auto"]
behaviour_learner = ["Q"]
behaviour_update = ["ESARSA"]
exploration_param = [0.1]
demon_learner = ["SR"]
demon_update = ["TB"]
num_tilings = [8]
num_tiles = [4]
exploring_starts= ["beg"]
