[config]
save_dir = "OneDTMaze_No_Reward_ESARSA"
exp_file = "experiments/1d-tmaze.jl"
exp_module_name = "OneDTmazeExperiment"
exp_func_name = "main_experiment"
arg_iter_type = "iter"

[static_args]

steps = 50000

logger_keys = ["ONEDTMAZEERROR", "ONED_GOAL_VISITATION", "EPISODE_LENGTH", "INTRINSIC_REWARD", "BEHAVIOUR_ACTION_VALUES"]
logger_interval = 100
# Behaviour Items
behaviour_alpha_init = 0.1 # Will be 1/tilings from sweep
behaviour_gamma = 0.90
behaviour_reward_projector = "tilecoding"
behaviour_rp_tilings = 1
behaviour_rp_tiles = 1
exploration_strategy = "epsilon_greedy"
# behaviour_trace = "AccumulatingTraces"
behaviour_lambda = 0.95
behaviour_w_init = 0.0

# Demon Attributes

demon_alpha_init = 0.1 # Will be 1/tilings from sweep
demon_discounts = 0.9
demon_lambda = 0.9
demon_policy_type = "greedy_to_cumulant"
demon_trace = "AccumulatingTraces"

# demon_learner = "SR"
demon_rep = "ideal_martha"
# demon_update = "TB"
# demon_eta = 0.15
demon_opt = "Auto"

# Environment Config
constant_target= [-10.0,10.0]
distractor = [1.0, 5.0]
drifter = [1.0, 0.1] # drifter is the sqrt(0.01)
env_step_penalty = -1.0


# exploring_starts="beg"

# Agent and Logger
horde_type = "regular"
intrinsic_reward = "no_reward"

use_external_reward = true

# num_tilings = 8
# num_tiles = 2


[sweep_args]
seed = "1:15"
cumulant_schedule = ["DrifterDistractor"]
eta = "5.0.^(-3:-1)"
behaviour_opt = ["Auto"]
behaviour_learner = ["Q"]
behaviour_update = ["ESARSA"]
exploration_param = [0.1]
demon_learner = ["NoLearner"]
demon_update = ["TB"]
# num_tilings = [1]
# num_tiles = [16]
tiling_structure = [[1,8],[2,8],[16,2],[32,2],[1,16]]

exploring_starts= ["beg"]
behaviour_trace = ["AccumulatingTraces"]
