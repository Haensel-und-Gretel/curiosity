[config]
save_dir = "TwoDGridWorld_gpi_simple"
exp_file = "experiments/2d-gridworld.jl"
exp_module_name = "TwoDGridWorldExperiment"
exp_func_name = "main_experiment"
arg_iter_type = "iter"

[static_args]

steps = 40000
# steps = 10

logger_keys = ["TWODGRIDWORLDERROR", "TWODGRIDWORLDERRORDPI", "ONED_GOAL_VISITATION", "EPISODE_LENGTH", "INTRINSIC_REWARD", "BEHAVIOUR_ACTION_VALUES"]
logger_interval = 100

# Behaviour Items

behaviour_gamma = 0.95

exploration_strategy = "epsilon_greedy"
behaviour_lambda = 0.9
behaviour_w_init = 0.0
behaviour_trace = "ReplacingTraces"
behaviour_reward_projector = "state_agg"
behaviour_bpd = 5

# Demon Attributes
demon_gamma = 0.95
demon_lambda = 0.9
demon_policy_type = "greedy_to_cumulant"
demon_trace = "AccumulatingTraces"
demon_rep = "ideal"
demon_interest_set = "2dOpenWorld_center"
demon_normalize_interest = true

# Agent and Logger
horde_type = "regular"
intrinsic_reward = "no_reward"
use_external_reward = true
behaviour_opt = "Auto"
demon_opt = "Auto"
behaviour_learner = "GPI"
behaviour_update = "TB"


# Environment Config
cumulant_schedule = "DrifterDistractor"
constant_target= [-10.0,10.0]
distractor = [1.0, 1]
drifter = [1.0, 0.07071] # Std here. Equivalent variance of 0.005
env_step_penalty = -1.0


[sweep_args]
seed = "1:2"

alpha_init = [0.1]
eta = [0.04, 0.2]
emphasis_clip_threshold = [10.0]

exploration_param = [0.1]
demon_learner = ["SR"]
demon_update = ["ETB","TB", "InterestTB"]
tiling_structure = [[16, 2]]
start_dist = ["uniform"]
