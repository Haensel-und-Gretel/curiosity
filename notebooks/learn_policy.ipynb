{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Curiosity.MountainCarUtils"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Curiosity, Statistics, Plots, FileIO, BSON\n",
    "using Random, StatsBase, RollingFunctions\n",
    "using GVFHordes\n",
    "\n",
    "const MCU = Curiosity.MountainCarUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulant\n",
    "struct Reward end\n",
    "\n",
    "(c::Reward)(;kwargs...) = kwargs[:r]\n",
    "\n",
    "struct ConstantDiscount{F}\n",
    "    val::F\n",
    "end\n",
    "   \n",
    "(d::ConstantDiscount)(;kwargs...) = d.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "construct_env (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment \n",
    "function construct_env()\n",
    "    normalized = true\n",
    "    env = MountainCar(0.0, 0.0, normalized)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "construct_agent (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent\n",
    "function construct_agent(numtilings, numtiles, lu_str, α, λ, ϵ, γ)\n",
    "    obs_size = 2\n",
    "    fc = Curiosity.SparseTileCoder(numtilings, numtiles, obs_size)\n",
    "    feature_size = size(fc)\n",
    "\n",
    "    lu = if lu_str == \"ESARSA\"\n",
    "        ESARSA(lambda=λ, opt=Curiosity.Descent(α))\n",
    "    elseif lu_str == \"SARSA\"\n",
    "        SARSA(lambda=λ, opt=Curiosity.Descent(α))\n",
    "    elseif lu_str == \"TB\"\n",
    "        TB(lambda=λ, opt=Curiosity.Descent(α))\n",
    "    else\n",
    "        throw(ArgumentError(\"$(lu_str) Not a valid behaviour learning update\"))\n",
    "    end\n",
    "#     (update, num_features, num_actions, num_demons, w_init)\n",
    "    learner = LinearQLearner(lu, feature_size, 3, 1,0)\n",
    "    exploration = EpsilonGreedy(ϵ)\n",
    "    cumulant = Reward()\n",
    "    discount = ConstantDiscount(γ)\n",
    "    \n",
    "    b_gvf = make_behaviour_gvf(learner, discount, fc, exploration)\n",
    "    b_demons = Horde([b_gvf])\n",
    "\n",
    "    Curiosity.PolicyLearner(learner, \n",
    "                            fc, \n",
    "                            exploration, \n",
    "                            discount, \n",
    "                            cumulant, \n",
    "                            zeros(2), \n",
    "                            0,\n",
    "                            b_demons)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_behaviour_gvf (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_behaviour_gvf(behaviour_learner, γ, fc, exploration_strategy)\n",
    "    function b_π(state_constructor, learner, exploration_strategy; kwargs...)\n",
    "        s = state_constructor(kwargs[:state_t])\n",
    "        preds = learner(s)\n",
    "        return exploration_strategy(preds)[kwargs[:action_t]]\n",
    "    end\n",
    "    GVF_policy = GVFParamFuncs.FunctionalPolicy((;kwargs...) -> b_π(fc, behaviour_learner, exploration_strategy; kwargs...))\n",
    "    BehaviourGVF = GVF(GVFParamFuncs.RewardCumulant(), GVFParamFuncs.ConstantDiscount(γ), GVF_policy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32[0.58050555, 0.40556338]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 3-element Vector{Float64} at index [  [1  ]  =  1\n  [3  ]  =  1\n  [4  ]  =  1\n  [5  ]  =  1\n  [6  ]  =  1\n  [8  ]  =  1\n  [9  ]  =  1\n  [10 ]  =  1]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 3-element Vector{Float64} at index [  [1  ]  =  1\n  [3  ]  =  1\n  [4  ]  =  1\n  [5  ]  =  1\n  [6  ]  =  1\n  [8  ]  =  1\n  [9  ]  =  1\n  [10 ]  =  1]",
      "",
      "Stacktrace:",
      "  [1] throw_boundserror(A::Vector{Float64}, I::Tuple{SparseArrays.SparseVector{Int64, Int64}})",
      "    @ Base ./abstractarray.jl:651",
      "  [2] checkbounds",
      "    @ ./abstractarray.jl:616 [inlined]",
      "  [3] _getindex",
      "    @ ./multidimensional.jl:831 [inlined]",
      "  [4] getindex",
      "    @ ./abstractarray.jl:1170 [inlined]",
      "  [5] (::var\"#b_π#15\"{var\"#b_π#12#16\"})(state_constructor::TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, learner::QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, exploration_strategy::EpsilonGreedy; kwargs::Base.Iterators.Pairs{Symbol, Any, NTuple{5, Symbol}, NamedTuple{(:state_t, :action_t, :state_tp1, :action_tp1, :reward), Tuple{Vector{Float64}, SparseArrays.SparseVector{Int64, Int64}, Vector{Float32}, Int64, Float32}}})",
      "    @ Main ./In[11]:5",
      "  [6] (::var\"#13#17\"{var\"#13#14#18\"{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy}})(; kwargs::Base.Iterators.Pairs{Symbol, Any, NTuple{5, Symbol}, NamedTuple{(:state_t, :action_t, :state_tp1, :action_tp1, :reward), Tuple{Vector{Float64}, SparseArrays.SparseVector{Int64, Int64}, Vector{Float32}, Int64, Float32}}})",
      "    @ Main ./In[11]:7",
      "  [7] #get#10",
      "    @ ~/Documents/Masters/curiosity/src/GVFHordes/src/gvf/policy.jl:73 [inlined]",
      "  [8] #5",
      "    @ ~/Documents/Masters/curiosity/src/GVFHordes/src/GVFHordes.jl:116 [inlined]",
      "  [9] iterate",
      "    @ ./generator.jl:47 [inlined]",
      " [10] _collect(c::Vector{GVF{GVFHordes.GVFParamFuncs.RewardCumulant, GVFHordes.GVFParamFuncs.ConstantDiscount{ConstantDiscount{Float64}}, GVFHordes.GVFParamFuncs.FunctionalPolicy{var\"#13#17\"{var\"#13#14#18\"{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy}}}}}, itr::Base.Generator{Vector{GVF{GVFHordes.GVFParamFuncs.RewardCumulant, GVFHordes.GVFParamFuncs.ConstantDiscount{ConstantDiscount{Float64}}, GVFHordes.GVFParamFuncs.FunctionalPolicy{var\"#13#17\"{var\"#13#14#18\"{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy}}}}}, GVFHordes.var\"#5#8\"{Base.Iterators.Pairs{Symbol, Any, NTuple{5, Symbol}, NamedTuple{(:state_t, :action_t, :state_tp1, :action_tp1, :reward), Tuple{Vector{Float64}, SparseArrays.SparseVector{Int64, Int64}, Vector{Float32}, Int64, Float32}}}}}, #unused#::Base.EltypeUnknown, isz::Base.HasShape{1})",
      "    @ Base ./array.jl:691",
      " [11] collect_similar",
      "    @ ./array.jl:606 [inlined]",
      " [12] map",
      "    @ ./abstractarray.jl:2294 [inlined]",
      " [13] #get#2",
      "    @ ~/Documents/Masters/curiosity/src/GVFHordes/src/GVFHordes.jl:116 [inlined]",
      " [14] get_demon_parameters(lu::TB{Flux.Optimise.Descent, AccumulatingTraces}, learner::QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, demons::Horde{GVF{GVFHordes.GVFParamFuncs.RewardCumulant, GVFHordes.GVFParamFuncs.ConstantDiscount{ConstantDiscount{Float64}}, GVFHordes.GVFParamFuncs.FunctionalPolicy{var\"#13#17\"{var\"#13#14#18\"{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy}}}}}, obs::Vector{Float64}, state::SparseArrays.SparseVector{Int64, Int64}, action::SparseArrays.SparseVector{Int64, Int64}, next_obs::Vector{Float32}, next_state::Int64, next_action::Int64, env_reward::Float32)",
      "    @ Curiosity ~/Documents/Masters/curiosity/src/updates/TB.jl:15",
      " [15] update!(lu::TB{Flux.Optimise.Descent, AccumulatingTraces}, learner::QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, demons::Horde{GVF{GVFHordes.GVFParamFuncs.RewardCumulant, GVFHordes.GVFParamFuncs.ConstantDiscount{ConstantDiscount{Float64}}, GVFHordes.GVFParamFuncs.FunctionalPolicy{var\"#13#17\"{var\"#13#14#18\"{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy}}}}}, obs::Vector{Float64}, next_obs::Vector{Float32}, state::SparseArrays.SparseVector{Int64, Int64}, action::SparseArrays.SparseVector{Int64, Int64}, next_state::Int64, next_action::Int64, is_terminal::Bool, behaviour_pi_func::Curiosity.var\"#32#33\"{Curiosity.PolicyLearner{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy, ConstantDiscount{Float64}, Reward, Vector{Float64}, Horde{GVF{GVFHordes.GVFParamFuncs.RewardCumulant, GVFHordes.GVFParamFuncs.ConstantDiscount{ConstantDiscount{Float64}}, GVFHordes.GVFParamFuncs.FunctionalPolicy{var\"#13#17\"{var\"#13#14#18\"{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy}}}}}}}, env_reward::Float32)",
      "    @ Curiosity ~/Documents/Masters/curiosity/src/updates/TB.jl:38",
      " [16] update!(::QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, ::Horde{GVF{GVFHordes.GVFParamFuncs.RewardCumulant, GVFHordes.GVFParamFuncs.ConstantDiscount{ConstantDiscount{Float64}}, GVFHordes.GVFParamFuncs.FunctionalPolicy{var\"#13#17\"{var\"#13#14#18\"{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy}}}}}, ::Vector{Float64}, ::Vector{Float32}, ::SparseArrays.SparseVector{Int64, Int64}, ::SparseArrays.SparseVector{Int64, Int64}, ::Int64, ::Int64, ::Bool, ::Function, ::Float32)",
      "    @ Curiosity ~/Documents/Masters/curiosity/src/learner.jl:13",
      " [17] step!(pl::Curiosity.PolicyLearner{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy, ConstantDiscount{Float64}, Reward, Vector{Float64}, Horde{GVF{GVFHordes.GVFParamFuncs.RewardCumulant, GVFHordes.GVFParamFuncs.ConstantDiscount{ConstantDiscount{Float64}}, GVFHordes.GVFParamFuncs.FunctionalPolicy{var\"#13#17\"{var\"#13#14#18\"{QLearner{Matrix{Float64}, TB{Flux.Optimise.Descent, AccumulatingTraces}}, TileCoder{SparseArrays.SparseVector{Int64, Ti} where Ti<:Integer}, EpsilonGreedy}}}}}}, o_tp1::Vector{Float32}, rew::Float32, term::Bool)",
      "    @ Curiosity ~/Documents/Masters/curiosity/src/LearnedPolicy.jl:78",
      " [18] top-level scope",
      "    @ ./In[12]:44",
      " [19] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [20] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "function make_behaviour_gvf(behaviour_learner, γ, fc, exploration_strategy)\n",
    "    function b_π(state_constructor, learner, exploration_strategy; kwargs...)\n",
    "        s = state_constructor(kwargs[:state_t])\n",
    "        preds = learner(s)\n",
    "        return exploration_strategy(preds)[kwargs[:action_t]]\n",
    "    end\n",
    "    GVF_policy = GVFParamFuncs.FunctionalPolicy((;kwargs...) -> b_π(fc, behaviour_learner, exploration_strategy; kwargs...))\n",
    "    BehaviourGVF = GVF(GVFParamFuncs.RewardCumulant(), GVFParamFuncs.ConstantDiscount(γ), GVF_policy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\n\tBad window span (100) for length 0.\n",
     "output_type": "error",
     "traceback": [
      "\n\tBad window span (100) for length 0.\n",
      "",
      "Stacktrace:",
      " [1] nrolled",
      "   @ ~/.julia/packages/RollingFunctions/4Jh9c/src/support.jl:20 [inlined]",
      " [2] rolling(fun::typeof(mean), data::Vector{Float64}, windowspan::Int64)",
      "   @ RollingFunctions ~/.julia/packages/RollingFunctions/4Jh9c/src/roll/rolling.jl:7",
      " [3] rollmean(data::Vector{Float64}, windowspan::Int64)",
      "   @ RollingFunctions ~/.julia/packages/RollingFunctions/4Jh9c/src/roll/rollstats.jl:14",
      " [4] top-level scope",
      "   @ In[26]:1",
      " [5] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [6] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "plot(rollmean(ret, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
